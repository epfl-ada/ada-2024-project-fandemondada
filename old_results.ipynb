{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.save_tar_gz import tar_gz_to_csv\n",
    "from src.data.load_data import load_data_from_csv\n",
    "from src.utils.data_utils import *\n",
    "from src.data.additional_data import *\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import src.data.wrangling as wrangling\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and wrangling the data\n",
    "\n",
    "For each dataset, we will clean the data by removing duplicates, missing values, and irrelevant columns.\n",
    "To remove missing values we'll use the following strategy:\n",
    "We'll extract a new column containing a boolean value indicating if the row has missing values. And replace the missing values by 0. This can be useful in a logistic regression if having a missing value at field x actually yields some information.\n",
    "\n",
    "N.B.: since the datasets are quite heavy, we overwrite the raw files with the wrangled ones instead of saving new files. If we want the raw files again, we have to load again the tar_gz_to_csv function as explained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/raw\"\n",
    "Ratebeer_path = lambda path: f\"{data_path}/Ratebeer\"\n",
    "BeerAdvocate_path = lambda path: f\"{data_path}/BeerAdvocate\"\n",
    "Matched_path = lambda path: f\"{data_path}/MatchedBeerData\"\n",
    "clean_path = \"data/clean\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning BeerAdvocate data\n",
    "\n",
    "We'll start by cleaning the BeerAdvocate data. We'll clean the users, ratings, beers, and breweries data.\n",
    "For users, we'll only focus on american users. \n",
    "We'll filter the users by their location and keep only the ones that have a location in the USA. Same with ratings we'll remove those not made by american users. We also remove the text reviews as we won't use them. Finally the missing data are handled as explained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangling.clean_beer_advocate(\n",
    "    raw_data_path=BeerAdvocate_path(data_path),\n",
    "    clean_data_path=BeerAdvocate_path(clean_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning RateBeer data\n",
    "\n",
    "The cleaning process is exactly the same as for BeerAdvocate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangling.clean_ratebeer(\n",
    "    raw_data_path=Ratebeer_path(data_path),\n",
    "    clean_data_path=Ratebeer_path(clean_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Matched data\n",
    "\n",
    "Here the cleaning is a bit different as we have to match the data from BeerAdvocate and RateBeer.\n",
    "As the columns have multiple types (the first row contains the name of the column in the original dataset), we have to clean them first. We'll delete the first row and append it to the column names so that they are more readable (for example ra_1 becomes ra_text). We'll then convert the columns to the correct type and remove the rows with missing values. The rest of the cleaning process is the same as for the other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangling.clean_matched_data(\n",
    "    raw_data_path=Matched_path(data_path),\n",
    "    clean_data_path=Matched_path(clean_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example of possible plot, below is the statewise Real Personal consumption expenditure per capita for the year 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse distribution of US users per state\n",
    "\n",
    "This part displays the distribution of users per US state. There are more than 130'000 users in America, not evenly distributed. The state with the most users has more than 14'000 of them, whereas the states with the least amount of users have only a couple hundreds of them. These numbers are reasonnably well correlated with the population in each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "\n",
    "users_matched = data_matched['matched_beer_data_users.csv']\n",
    "users_ba = data_ba['BeerAdvocate_users.csv']\n",
    "users_rb = data_rb['RateBeer_users.csv']\n",
    "users_ba = users_ba.dropna(subset=['location'])\n",
    "users_rb = users_rb.dropna(subset=['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of American users\n",
    "\n",
    "users_matched_usa = users_matched[users_matched['ba.1'].str.startswith('United States')]\n",
    "users_ba_usa = users_ba[users_ba['location'].str.startswith('United States')]\n",
    "users_rb_usa = users_rb[users_rb['location'].str.startswith('United States')]\n",
    "\n",
    "print(f\"Number of matched users in USA: {users_matched_usa.shape[0]}\")\n",
    "print(f\"Number of BeerAdvocate users in USA: {users_ba_usa.shape[0]}\")\n",
    "print(f\"Number of RateBeer users in USA: {users_rb_usa.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the statewise distribution of users\n",
    "\n",
    "states_usa_ba = users_ba_usa['location'].apply(lambda x: x.split(', ')[1])\n",
    "states_usa_rb = users_rb_usa['location'].apply(lambda x: x.split(', ')[1])\n",
    "\n",
    "# print(f\"USA states represented in BeerAdvocate: {len(states_usa_ba.unique())}\")\n",
    "# print(f\"USA states represented in RateBeer: {len(states_usa_rb.unique())}\")\n",
    "\n",
    "# print(f\"Number of users per state in BeerAdvocate: {states_usa_ba.value_counts()}\")\n",
    "# print(f\"Number of users per state in RateBeer: {states_usa_rb.value_counts()}\")\n",
    "\n",
    "users_per_state_ba = states_usa_ba.value_counts().to_dict()\n",
    "users_per_state_rb = states_usa_rb.value_counts().to_dict()\n",
    "users_per_state_barb = {k: (users_per_state_ba[k] + users_per_state_rb[k]) for k in users_per_state_ba.keys()}\n",
    "\n",
    "states = users_per_state_barb.keys()\n",
    "users = users_per_state_barb.values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.bar(states, users)\n",
    "ax.set_ylabel('Number of users')\n",
    "ax.set_xlabel('States')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse distribution of US Breweries per state\n",
    "\n",
    "This part displays the distribution of breweries per US state. There are more than 10'000 breweries in America, not evenly distributed. The state with the most breweries has about 1'800 of them, whereas the states with the least amount of users have a couple tens of them. These numbers are reasonnably well correlated with the population in each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "\n",
    "breweries_matched = data_matched['matched_beer_data_breweries.csv']\n",
    "breweries_ba = data_ba['BeerAdvocate_breweries.csv']\n",
    "breweries_rb = data_rb['RateBeer_breweries.csv']\n",
    "breweries_ba = breweries_ba.dropna(subset=['location'])\n",
    "breweries_rb = breweries_rb.dropna(subset=['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of American breweries\n",
    "\n",
    "breweries_matched_usa = breweries_matched[breweries_matched['ba.1'].str.startswith('United States')]\n",
    "breweries_ba_usa = breweries_ba[breweries_ba['location'].str.startswith('United States')]\n",
    "breweries_rb_usa = breweries_rb[breweries_rb['location'].str.startswith('United States')]\n",
    "\n",
    "print(f\"Number of matched breweries in USA: {breweries_matched_usa.shape[0]}\")\n",
    "print(f\"Number of BeerAdvocate breweries in USA: {breweries_ba_usa.shape[0]}\")\n",
    "print(f\"Number of RateBeer breweries in USA: {breweries_rb_usa.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the statewise distribution of breweries\n",
    "\n",
    "breweries_name_split_ba = breweries_ba_usa['location'].apply(lambda x: len(x.split(',')))\n",
    "breweries_filtered_ba = breweries_ba_usa[breweries_name_split_ba == 2]\n",
    "breweries_filtered_ba = breweries_filtered_ba[breweries_filtered_ba['location'] != 'United States, United States']\n",
    "breweries_per_states_ba = breweries_filtered_ba['location'].apply(lambda x: x.split(',')[1])\n",
    "\n",
    "breweries_name_split_rb = breweries_rb_usa['location'].apply(lambda x: len(x.split(',')))\n",
    "breweries_filtered_rb = breweries_rb_usa[breweries_name_split_rb == 2]\n",
    "breweries_filtered_rb['location'] = breweries_filtered_rb['location'].mask(breweries_filtered_rb['location'] == 'United States, Washington DC', 'United States, California')\n",
    "breweries_per_states_rb = breweries_filtered_rb['location'].apply(lambda x: x.split(',')[1])\n",
    "\n",
    "# print(f\"USA states with breweries represented in BeerAdvocate: {len(breweries_per_states_ba.unique())}\")\n",
    "# print(f\"USA states with breweries represented in RateBeer: {len(breweries_per_states_rb.unique())}\")\n",
    "\n",
    "# print(f\"Number of breweries per state in BeerAdvocate: {breweries_per_states_ba.value_counts()}\")\n",
    "# print(f\"Number of breweries per state in RateBeer: {breweries_per_states_rb.value_counts()}\")\n",
    "\n",
    "breweries_per_state_ba = breweries_per_states_ba.value_counts().to_dict()\n",
    "breweries_per_state_rb = breweries_per_states_rb.value_counts().to_dict()\n",
    "\n",
    "# delete the space at the start of each key\n",
    "breweries_per_state_ba = {k[1:]: v for k, v in breweries_per_state_ba.items()}\n",
    "breweries_per_state_rb = {k[1:]: v for k, v in breweries_per_state_rb.items()}\n",
    "\n",
    "breweries_per_state_barb = {k: (breweries_per_state_ba[k] + breweries_per_state_rb[k]) for k in breweries_per_state_ba.keys()}\n",
    "\n",
    "states = breweries_per_state_barb.keys()\n",
    "users = breweries_per_state_barb.values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.bar(states, users)\n",
    "ax.set_ylabel('Number of users')\n",
    "ax.set_xlabel('States')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse ratio of users per brewery in each state\n",
    "\n",
    "This part displays the ratio of users per brewery in each American state. Compared to the two previously computed distribution, the ranking is less strongly correlated with the population of each states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of users per brewery in each state\n",
    "users_per_brewery_barb = {k: (users_per_state_barb[k] / breweries_per_state_barb[k]) for k in users_per_state_ba.keys()}\n",
    "print(users_per_brewery_barb)\n",
    "\n",
    "# Sort so easier to view plot\n",
    "sorted_users_per_brewery_ba = dict(sorted(users_per_brewery_barb.items(), key=lambda item: item[1]))\n",
    "\n",
    "states = sorted_users_per_brewery_ba.keys()\n",
    "users_per_brewery = sorted_users_per_brewery_ba.values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.bar(states, users_per_brewery)\n",
    "ax.set_ylabel('Number of users per brewery')\n",
    "ax.set_xlabel('States')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data from Census\n",
    "\n",
    "Print the data from the urban vs rural census. As mentioned in the README, this data will probably not be used in the final rapport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_path = 'data/raw/Census/'\n",
    "file_name_2020 = 'DECENNIALCD1182020.H2_rural_urban_US.csv'\n",
    "file_name_2010 = 'DECENNIALCD1162010.H2_rural_urban_US.csv'\n",
    "\n",
    "urban_2020_df = load_urban_frac_df(census_path, file_name_2020).reset_index()\n",
    "urban_2010_df = load_urban_frac_df(census_path, file_name_2010).reset_index()\n",
    "\n",
    "print(urban_2020_df.head())\n",
    "print(urban_2010_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from BEA\n",
    "\n",
    "This dataframe contains various statewise economic indicators, more info in the source or in the index of the .csv. The following dictionnary gives a first overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/raw/IncomeBEA/\"\n",
    "filename = \"GDP_PersonalIncome_USState.csv\"\n",
    "\n",
    "# DPI: disposable personal income\n",
    "# PI: personal income\n",
    "# PCE: personal consumption expenditures\n",
    "# GDP: Gross Domestic Product\n",
    "BEO_income_index = {\n",
    "    'RealGDP': 1, \n",
    "    'RealPI':2, \n",
    "    'RealPCE': 3,\n",
    "    'GDP': 4,  \n",
    "    'PI': 5, \n",
    "    'DPI': 6,\n",
    "    'PCE': 7,\n",
    "    'RealPI/cap': 8,\n",
    "    'RealPCE/cap': 9,\n",
    "    'PI/cap': 10,\n",
    "    'DPI/cap': 11,\n",
    "    'PCE/cap': 12     \n",
    "    #13 14 15 useless\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BEA = loadBEA(path, filename, BEO_income_index)\n",
    "BEA = get_mutliIndex_sub_df(BEA, ['RealPCE/cap'], ['2010'])\n",
    "\n",
    "states = [x[0] for x in BEA.index.values]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.bar(states, BEA['RealPCE/cap'])\n",
    "ax.set_ylabel('Real Personal Consumption expenditures per capita')\n",
    "ax.set_xlabel('States')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of users per habitant in each state\n",
    "This allows us to see if we have enough users per state, compared to its population. These values range approximately between 500 and 3'000 inhabitant per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the statewise population by adding the rural and urban population\n",
    "\n",
    "if all(col in urban_2010_df.columns for col in ['urban_pop', 'rural_pop', 'urban_frac']):\n",
    "    urban_2010_df = urban_2010_df.drop(columns=['urban_pop', 'rural_pop', 'urban_frac'])\n",
    "urban_2010_dict = urban_2010_df.set_index('state').to_dict()['total_pop']\n",
    "\n",
    "# delete keys states that are not in the 50 official\n",
    "urban_2010_dict = {k: v for k, v in urban_2010_dict.items() if k in users_per_state_barb.keys()}\n",
    "\n",
    "# number of habitants per user in each state\n",
    "users_per_habitant = {k: (urban_2010_dict[k] / users_per_state_barb[k]) for k in users_per_state_barb.keys()}\n",
    "print(users_per_habitant)\n",
    "\n",
    "states = users_per_habitant.keys()\n",
    "users_per_habitant = users_per_habitant.values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "ax.bar(states, users_per_habitant)\n",
    "ax.set_ylabel('Number of users per habitant')\n",
    "ax.set_xlabel('States')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alcohol consumption per capita per state\n",
    "\n",
    "This loads the statewise alcohol data table and displays the two most interesting column to us, the per capita beer ethanol consumption and per capita nominal beer consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icpsr_path = 'data/raw/OPENICPSR/OPENICPSR_apparent_per_capita_alcohol_consumption.csv'\n",
    "data_icpsr = load_icpsr(icpsr_path) # load + format data\n",
    "print('available years: ', data_icpsr.keys())\n",
    "data_icpsr['2016'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age distribution per state\n",
    "\n",
    "This loads the statewise age distribution. They are expressed in two ways per 5 years age interval, in absolute count and in relative percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_path = 'data/raw/GeneralPopulationAge/DECENNIALDP2020.DP1-2024-11-14T134434.csv'\n",
    "age_total, age_male, age_female = load_age_data(age_path, load_gender = True)\n",
    "age_total.head(5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
